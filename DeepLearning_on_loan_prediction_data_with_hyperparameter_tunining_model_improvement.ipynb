{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPnFRoekxgMcGqHX0ECyqL3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Parinita-Jain/DeepLearning/blob/main/DeepLearning_on_loan_prediction_data_with_hyperparameter_tunining_model_improvement.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "9WJ9E1IdzQ2S"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data=pd.read_csv(\"loan_prediction_data.csv\")\n",
        "data.head()"
      ],
      "metadata": {
        "id": "mIOI8oJp0mod",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "outputId": "dbb10433-c73d-4994-fd80-ff6df8d12fb6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Loan_ID  Gender  Married  Dependents  Education  Self_Employed  \\\n",
              "0  LP001002       0        0    0.000000          1              0   \n",
              "1  LP001003       0        1    0.333333          1              0   \n",
              "2  LP001005       0        1    0.000000          1              1   \n",
              "3  LP001006       0        1    0.000000          0              0   \n",
              "4  LP001008       0        0    0.000000          1              0   \n",
              "\n",
              "   ApplicantIncome  CoapplicantIncome  LoanAmount  Loan_Amount_Term  \\\n",
              "0         0.070489           0.000000    0.198860           0.74359   \n",
              "1         0.054830           0.036192    0.172214           0.74359   \n",
              "2         0.035250           0.000000    0.082489           0.74359   \n",
              "3         0.030093           0.056592    0.160637           0.74359   \n",
              "4         0.072356           0.000000    0.191027           0.74359   \n",
              "\n",
              "   Credit_History  Property_Area  Loan_Status  \n",
              "0               1            1.0            1  \n",
              "1               1            0.0            0  \n",
              "2               1            1.0            1  \n",
              "3               1            1.0            1  \n",
              "4               1            1.0            1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-436914bb-9f37-4a66-8637-8f16da263026\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Loan_ID</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Married</th>\n",
              "      <th>Dependents</th>\n",
              "      <th>Education</th>\n",
              "      <th>Self_Employed</th>\n",
              "      <th>ApplicantIncome</th>\n",
              "      <th>CoapplicantIncome</th>\n",
              "      <th>LoanAmount</th>\n",
              "      <th>Loan_Amount_Term</th>\n",
              "      <th>Credit_History</th>\n",
              "      <th>Property_Area</th>\n",
              "      <th>Loan_Status</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>LP001002</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.070489</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.198860</td>\n",
              "      <td>0.74359</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>LP001003</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.054830</td>\n",
              "      <td>0.036192</td>\n",
              "      <td>0.172214</td>\n",
              "      <td>0.74359</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>LP001005</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.035250</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.082489</td>\n",
              "      <td>0.74359</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>LP001006</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.030093</td>\n",
              "      <td>0.056592</td>\n",
              "      <td>0.160637</td>\n",
              "      <td>0.74359</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>LP001008</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.072356</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.191027</td>\n",
              "      <td>0.74359</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-436914bb-9f37-4a66-8637-8f16da263026')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-436914bb-9f37-4a66-8637-8f16da263026 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-436914bb-9f37-4a66-8637-8f16da263026');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.isnull().sum()"
      ],
      "metadata": {
        "id": "QRskmaGX0mqV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cdc3947f-3eef-4030-ec85-5812710c673e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Loan_ID              0\n",
              "Gender               0\n",
              "Married              0\n",
              "Dependents           0\n",
              "Education            0\n",
              "Self_Employed        0\n",
              "ApplicantIncome      0\n",
              "CoapplicantIncome    0\n",
              "LoanAmount           0\n",
              "Loan_Amount_Term     0\n",
              "Credit_History       0\n",
              "Property_Area        0\n",
              "Loan_Status          0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.dtypes"
      ],
      "metadata": {
        "id": "scH8YWfZ0msV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b173dbe-cc11-4513-983c-45c2c3253752"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Loan_ID               object\n",
              "Gender                 int64\n",
              "Married                int64\n",
              "Dependents           float64\n",
              "Education              int64\n",
              "Self_Employed          int64\n",
              "ApplicantIncome      float64\n",
              "CoapplicantIncome    float64\n",
              "LoanAmount           float64\n",
              "Loan_Amount_Term     float64\n",
              "Credit_History         int64\n",
              "Property_Area        float64\n",
              "Loan_Status            int64\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.drop(\"Loan_ID\",axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "qngHSNyj0muG"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X=data.drop(\"Loan_Status\",axis=1)\n",
        "y=data[\"Loan_Status\"]"
      ],
      "metadata": {
        "id": "7FWiheoq0mxc"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "xtrain,xtest,ytrain,ytest=train_test_split(X,y,random_state=10,test_size=0.2,stratify=y)"
      ],
      "metadata": {
        "id": "B9upEw9T0m1f"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras \n",
        "from keras import Input,Model\n",
        "from keras.layers import InputLayer,Dense\n",
        "from keras.models import Sequential\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "uu1Dd1X-0m40"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_neurons=xtrain.shape[1]\n",
        "output_neurons=1\n",
        "no_of_hidden_layers=2\n",
        "neuron_hidden_layer_1=10\n",
        "neuron_hidden_layer_2=5"
      ],
      "metadata": {
        "id": "-65QRbfU0m7j"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=tf.keras.Sequential([Input(shape=(input_neurons,)),\n",
        "                           Dense(units=neuron_hidden_layer_1,activation=\"relu\"),\n",
        "                           Dense(units=neuron_hidden_layer_2,activation=\"relu\"),\n",
        "                           Dense(units=output_neurons,activation=\"sigmoid\")])\n",
        "\n",
        "'''\n",
        "X=tf.keras.Sequential([Input(shape=(input_neurons,)),\n",
        "hidden1=Dense(units=neuron_hidden_layer_1,activation=\"relu\")(X),\n",
        "hidden2=Dense(units=neuron_hidden_layer_2,activation=\"relu\")(hidden1),\n",
        "output=Dense(units=output_neurons,activation=\"sigmoid\")(hidden2)])\n",
        "#model_functional=Model(X,output)\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "P-1CaXVi3a_0",
        "outputId": "f4c41f5e-5f62-4166-9559-0ab11579e534"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nX=tf.keras.Sequential([Input(shape=(input_neurons,)),\\nhidden1=Dense(units=neuron_hidden_layer_1,activation=\"relu\")(X),\\nhidden2=Dense(units=neuron_hidden_layer_2,activation=\"relu\")(hidden1),\\noutput=Dense(units=output_neurons,activation=\"sigmoid\")(hidden2)])\\n#model_functional=Model(X,output)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=\"binary_crossentropy\",optimizer=\"Adam\",metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "ms5tQb1P3bBm"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_history=model.fit(xtrain,ytrain,validation_data=(xtest,ytest),epochs=20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KXsWxy9t3bD7",
        "outputId": "bbacf1d5-9100-462e-bd5b-7f2e8911360d"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "16/16 [==============================] - 1s 21ms/step - loss: 0.5902 - accuracy: 0.6864 - val_loss: 0.5862 - val_accuracy: 0.6911\n",
            "Epoch 2/20\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.5838 - accuracy: 0.6864 - val_loss: 0.5812 - val_accuracy: 0.6911\n",
            "Epoch 3/20\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.5809 - accuracy: 0.6864 - val_loss: 0.5769 - val_accuracy: 0.6911\n",
            "Epoch 4/20\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.5764 - accuracy: 0.6864 - val_loss: 0.5739 - val_accuracy: 0.6911\n",
            "Epoch 5/20\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.5732 - accuracy: 0.6864 - val_loss: 0.5701 - val_accuracy: 0.6911\n",
            "Epoch 6/20\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.5699 - accuracy: 0.6864 - val_loss: 0.5670 - val_accuracy: 0.6911\n",
            "Epoch 7/20\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.5658 - accuracy: 0.6864 - val_loss: 0.5633 - val_accuracy: 0.6992\n",
            "Epoch 8/20\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.5618 - accuracy: 0.6904 - val_loss: 0.5602 - val_accuracy: 0.6992\n",
            "Epoch 9/20\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.5573 - accuracy: 0.7026 - val_loss: 0.5566 - val_accuracy: 0.7073\n",
            "Epoch 10/20\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.5529 - accuracy: 0.7108 - val_loss: 0.5522 - val_accuracy: 0.7236\n",
            "Epoch 11/20\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.5481 - accuracy: 0.7352 - val_loss: 0.5484 - val_accuracy: 0.7236\n",
            "Epoch 12/20\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.5448 - accuracy: 0.7536 - val_loss: 0.5442 - val_accuracy: 0.7236\n",
            "Epoch 13/20\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.5384 - accuracy: 0.7556 - val_loss: 0.5415 - val_accuracy: 0.7480\n",
            "Epoch 14/20\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.5346 - accuracy: 0.7699 - val_loss: 0.5389 - val_accuracy: 0.7642\n",
            "Epoch 15/20\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.5318 - accuracy: 0.7862 - val_loss: 0.5356 - val_accuracy: 0.7642\n",
            "Epoch 16/20\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.5283 - accuracy: 0.7902 - val_loss: 0.5320 - val_accuracy: 0.7724\n",
            "Epoch 17/20\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.5248 - accuracy: 0.7984 - val_loss: 0.5290 - val_accuracy: 0.7805\n",
            "Epoch 18/20\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.5215 - accuracy: 0.7984 - val_loss: 0.5259 - val_accuracy: 0.7967\n",
            "Epoch 19/20\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.5190 - accuracy: 0.8045 - val_loss: 0.5226 - val_accuracy: 0.8130\n",
            "Epoch 20/20\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.5153 - accuracy: 0.8086 - val_loss: 0.5190 - val_accuracy: 0.8130\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction=model.predict(xtest)\n",
        "prediction"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18EvzZUO3bFm",
        "outputId": "c4daa675-5003-4461-c696-4dc62c483315"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 5ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.7121909 ],\n",
              "       [0.6568916 ],\n",
              "       [0.71209985],\n",
              "       [0.7528896 ],\n",
              "       [0.82743686],\n",
              "       [0.6331347 ],\n",
              "       [0.8159458 ],\n",
              "       [0.7512207 ],\n",
              "       [0.8139339 ],\n",
              "       [0.6425241 ],\n",
              "       [0.78101516],\n",
              "       [0.622961  ],\n",
              "       [0.74307287],\n",
              "       [0.8169115 ],\n",
              "       [0.6584804 ],\n",
              "       [0.7649915 ],\n",
              "       [0.7614754 ],\n",
              "       [0.7358593 ],\n",
              "       [0.7760944 ],\n",
              "       [0.7518686 ],\n",
              "       [0.6368715 ],\n",
              "       [0.83540905],\n",
              "       [0.7202111 ],\n",
              "       [0.74688774],\n",
              "       [0.7410644 ],\n",
              "       [0.7902615 ],\n",
              "       [0.774584  ],\n",
              "       [0.6414551 ],\n",
              "       [0.7988944 ],\n",
              "       [0.77642107],\n",
              "       [0.81519836],\n",
              "       [0.8353222 ],\n",
              "       [0.83450186],\n",
              "       [0.3494205 ],\n",
              "       [0.37641743],\n",
              "       [0.4668356 ],\n",
              "       [0.736204  ],\n",
              "       [0.82677096],\n",
              "       [0.7557719 ],\n",
              "       [0.8205465 ],\n",
              "       [0.8248574 ],\n",
              "       [0.64052856],\n",
              "       [0.77923566],\n",
              "       [0.8119832 ],\n",
              "       [0.43536672],\n",
              "       [0.836359  ],\n",
              "       [0.79568267],\n",
              "       [0.7289487 ],\n",
              "       [0.7242382 ],\n",
              "       [0.46979004],\n",
              "       [0.78019977],\n",
              "       [0.7109987 ],\n",
              "       [0.7781851 ],\n",
              "       [0.7635403 ],\n",
              "       [0.8268431 ],\n",
              "       [0.37788928],\n",
              "       [0.81643623],\n",
              "       [0.7297064 ],\n",
              "       [0.38840207],\n",
              "       [0.7149351 ],\n",
              "       [0.7346842 ],\n",
              "       [0.68149877],\n",
              "       [0.7840209 ],\n",
              "       [0.72922575],\n",
              "       [0.71252465],\n",
              "       [0.82518756],\n",
              "       [0.7632785 ],\n",
              "       [0.47642344],\n",
              "       [0.8255952 ],\n",
              "       [0.77311   ],\n",
              "       [0.3944396 ],\n",
              "       [0.72795635],\n",
              "       [0.68633157],\n",
              "       [0.75207025],\n",
              "       [0.7001381 ],\n",
              "       [0.82066923],\n",
              "       [0.7455327 ],\n",
              "       [0.6671975 ],\n",
              "       [0.62315583],\n",
              "       [0.38569093],\n",
              "       [0.825779  ],\n",
              "       [0.7041878 ],\n",
              "       [0.8263237 ],\n",
              "       [0.647174  ],\n",
              "       [0.6146872 ],\n",
              "       [0.46961835],\n",
              "       [0.7204739 ],\n",
              "       [0.81778854],\n",
              "       [0.8142561 ],\n",
              "       [0.8261225 ],\n",
              "       [0.77272344],\n",
              "       [0.81620514],\n",
              "       [0.79211473],\n",
              "       [0.42381743],\n",
              "       [0.77404964],\n",
              "       [0.81400704],\n",
              "       [0.80845565],\n",
              "       [0.39092076],\n",
              "       [0.75594527],\n",
              "       [0.7786558 ],\n",
              "       [0.79697496],\n",
              "       [0.70421684],\n",
              "       [0.7127462 ],\n",
              "       [0.82343316],\n",
              "       [0.7195758 ],\n",
              "       [0.6013726 ],\n",
              "       [0.8165373 ],\n",
              "       [0.77286905],\n",
              "       [0.817483  ],\n",
              "       [0.7123436 ],\n",
              "       [0.46384293],\n",
              "       [0.7378674 ],\n",
              "       [0.7557074 ],\n",
              "       [0.31205106],\n",
              "       [0.39420986],\n",
              "       [0.710992  ],\n",
              "       [0.7797666 ],\n",
              "       [0.83540004],\n",
              "       [0.7591388 ],\n",
              "       [0.7786986 ],\n",
              "       [0.81485635],\n",
              "       [0.38463143],\n",
              "       [0.8169015 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction=prediction.reshape(123,)"
      ],
      "metadata": {
        "id": "JXiiqYoV3bH2"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction_int=prediction>=0.5"
      ],
      "metadata": {
        "id": "ATHX6Om93bJd"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction_int=prediction_int.astype(np.int)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SESOaVk03bMc",
        "outputId": "57868f07-48c9-4255-84eb-29e45c0d28ea"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-44-e98897c67493>:1: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  prediction_int=prediction_int.astype(np.int)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_score(ytest,prediction_int)\n",
        "plt.plot(model_history.history[\"loss\"])\n",
        "plt.plot(model_history.history[\"val_loss\"])\n",
        "plt.title(\"model_loss\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.legend([\"train\",\"validation\"],loc=\"upper left\")\n",
        "plt.show()\n",
        "plt.plot(model_history.history[\"accuracy\"])\n",
        "plt.plot(model_history.history[\"val_accuracy\"])\n",
        "plt.title(\"model_accuracy\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.legend([\"train\",\"validation\"],loc=\"upper left\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "id": "xhrILhao3bOl",
        "outputId": "fa24f1ee-f52c-46ae-bf70-55de18d34c58"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model=Sequential()\n",
        "model.add(InputLayer(input_shape=(input_neurons,)))\n",
        "model.add(Dense(units=neuron_hidden_layer_1,activation=\"relu\"))\n",
        "model.add(Dense(units=neuron_hidden_layer_2,activation=\"relu\"))\n",
        "model.add(Dense(units=output_neurons,activation=\"sigmoid\"))\n",
        "model.summary()\n",
        "model.compile(loss=\"binary_crossentropy\",optimizer=\"Adam\",metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cGqNosoF3bSp",
        "outputId": "a7bf96cc-9bbf-4cdc-87b6-0a7ba79b7f4c"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_14 (Dense)            (None, 10)                120       \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 5)                 55        \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 1)                 6         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 181\n",
            "Trainable params: 181\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_history=model.fit(xtrain,ytrain,validation_data=(xtest,ytest),epochs=20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ko4wm8Y63bU9",
        "outputId": "3102e0e0-2f71-4b64-9262-1f848bea3dc4"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "16/16 [==============================] - 1s 16ms/step - loss: 0.6751 - accuracy: 0.5988 - val_loss: 0.6584 - val_accuracy: 0.7154\n",
            "Epoch 2/20\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6488 - accuracy: 0.7006 - val_loss: 0.6367 - val_accuracy: 0.7154\n",
            "Epoch 3/20\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6281 - accuracy: 0.7312 - val_loss: 0.6194 - val_accuracy: 0.7236\n",
            "Epoch 4/20\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6115 - accuracy: 0.7291 - val_loss: 0.6044 - val_accuracy: 0.7236\n",
            "Epoch 5/20\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.5979 - accuracy: 0.7312 - val_loss: 0.5931 - val_accuracy: 0.7317\n",
            "Epoch 6/20\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.5875 - accuracy: 0.7352 - val_loss: 0.5825 - val_accuracy: 0.7317\n",
            "Epoch 7/20\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.5775 - accuracy: 0.7434 - val_loss: 0.5746 - val_accuracy: 0.7398\n",
            "Epoch 8/20\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.5700 - accuracy: 0.7454 - val_loss: 0.5665 - val_accuracy: 0.7480\n",
            "Epoch 9/20\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.5625 - accuracy: 0.7515 - val_loss: 0.5607 - val_accuracy: 0.7480\n",
            "Epoch 10/20\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.5559 - accuracy: 0.7536 - val_loss: 0.5549 - val_accuracy: 0.7480\n",
            "Epoch 11/20\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.5496 - accuracy: 0.7597 - val_loss: 0.5501 - val_accuracy: 0.7724\n",
            "Epoch 12/20\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.5436 - accuracy: 0.7678 - val_loss: 0.5442 - val_accuracy: 0.7724\n",
            "Epoch 13/20\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.5385 - accuracy: 0.7699 - val_loss: 0.5390 - val_accuracy: 0.7805\n",
            "Epoch 14/20\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.5318 - accuracy: 0.7821 - val_loss: 0.5348 - val_accuracy: 0.7886\n",
            "Epoch 15/20\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.5271 - accuracy: 0.7862 - val_loss: 0.5304 - val_accuracy: 0.7967\n",
            "Epoch 16/20\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.5225 - accuracy: 0.7882 - val_loss: 0.5259 - val_accuracy: 0.7967\n",
            "Epoch 17/20\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.5178 - accuracy: 0.7882 - val_loss: 0.5226 - val_accuracy: 0.7967\n",
            "Epoch 18/20\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.5141 - accuracy: 0.7923 - val_loss: 0.5189 - val_accuracy: 0.7967\n",
            "Epoch 19/20\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.5103 - accuracy: 0.8004 - val_loss: 0.5163 - val_accuracy: 0.8049\n",
            "Epoch 20/20\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.5076 - accuracy: 0.8065 - val_loss: 0.5138 - val_accuracy: 0.8049\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction=model.predict(xtest)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JRt9oM5o3bWe",
        "outputId": "32367361-3d3c-4bfd-88cf-478c66f671ef"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 4ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# and rest of the steps"
      ],
      "metadata": {
        "id": "6APQ4Uoj3bZg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Hyperparameter tuning of NN-\n",
        "1. Change activation function of hidden layer\n",
        "2. increase hidden neurons\n",
        "3. increase hidden layers\n",
        "4. increase no. of epochs\n",
        "5. change optimizer\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "hWoDwEt-3bbP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "model=Sequential()\n",
        "model.add(InputLayer(input_shape=(input_neurons,)))\n",
        "model.add(Dense(units=neuron_hidden_layer_1,activation=\"tanh\"))\n",
        "model.add(Dense(units=neuron_hidden_layer_2,activation=\"tanh\"))\n",
        "model.add(Dense(units=output_neurons,activation=\"sigmoid\"))\n",
        "model.summary()\n",
        "model.compile(loss=\"binary_crossentropy\",optimizer=\"Adam\",metrics=[\"accuracy\"])\n",
        "model_history=model.fit(xtrain,ytrain,validation_data=(xtest,ytest),epochs=20)\n",
        "prediction=model.predict(xtest)\n",
        "prediction=prediction.reshape(123,)\n",
        "prediction_int=prediction>=0.5\n",
        "prediction_int=prediction_int.astype(np.int)\n",
        "print(accuracy_score(ytest,prediction_int))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qxPs5JR63beB",
        "outputId": "3bf72249-a453-4e48-d556-61c5c01d94d0"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_32 (Dense)            (None, 10)                120       \n",
            "                                                                 \n",
            " dense_33 (Dense)            (None, 5)                 55        \n",
            "                                                                 \n",
            " dense_34 (Dense)            (None, 1)                 6         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 181\n",
            "Trainable params: 181\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "16/16 [==============================] - 1s 17ms/step - loss: 0.7233 - accuracy: 0.4827 - val_loss: 0.6573 - val_accuracy: 0.6260\n",
            "Epoch 2/20\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6484 - accuracy: 0.6415 - val_loss: 0.6108 - val_accuracy: 0.6748\n",
            "Epoch 3/20\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6162 - accuracy: 0.6945 - val_loss: 0.5962 - val_accuracy: 0.6911\n",
            "Epoch 4/20\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.6050 - accuracy: 0.6925 - val_loss: 0.5912 - val_accuracy: 0.6911\n",
            "Epoch 5/20\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6000 - accuracy: 0.6925 - val_loss: 0.5867 - val_accuracy: 0.6911\n",
            "Epoch 6/20\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.5940 - accuracy: 0.6925 - val_loss: 0.5824 - val_accuracy: 0.6911\n",
            "Epoch 7/20\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.5887 - accuracy: 0.6945 - val_loss: 0.5784 - val_accuracy: 0.6992\n",
            "Epoch 8/20\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.5836 - accuracy: 0.6945 - val_loss: 0.5738 - val_accuracy: 0.6992\n",
            "Epoch 9/20\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.5787 - accuracy: 0.6945 - val_loss: 0.5702 - val_accuracy: 0.6992\n",
            "Epoch 10/20\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.5734 - accuracy: 0.6986 - val_loss: 0.5662 - val_accuracy: 0.6992\n",
            "Epoch 11/20\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.5686 - accuracy: 0.7006 - val_loss: 0.5619 - val_accuracy: 0.7154\n",
            "Epoch 12/20\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.5639 - accuracy: 0.7047 - val_loss: 0.5578 - val_accuracy: 0.7154\n",
            "Epoch 13/20\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.5591 - accuracy: 0.7067 - val_loss: 0.5541 - val_accuracy: 0.7480\n",
            "Epoch 14/20\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.5544 - accuracy: 0.7251 - val_loss: 0.5501 - val_accuracy: 0.7480\n",
            "Epoch 15/20\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.5501 - accuracy: 0.7617 - val_loss: 0.5468 - val_accuracy: 0.7724\n",
            "Epoch 16/20\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.5451 - accuracy: 0.7658 - val_loss: 0.5429 - val_accuracy: 0.7724\n",
            "Epoch 17/20\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.5409 - accuracy: 0.7699 - val_loss: 0.5386 - val_accuracy: 0.7886\n",
            "Epoch 18/20\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.5362 - accuracy: 0.7760 - val_loss: 0.5352 - val_accuracy: 0.7886\n",
            "Epoch 19/20\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.5318 - accuracy: 0.7882 - val_loss: 0.5318 - val_accuracy: 0.7886\n",
            "Epoch 20/20\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.5278 - accuracy: 0.7963 - val_loss: 0.5278 - val_accuracy: 0.7886\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "0.7886178861788617\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-54-7d227ce3efdb>:12: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  prediction_int=prediction_int.astype(np.int)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# increasing hidden neurons\n",
        "\n",
        "\n",
        "\n",
        "model=Sequential()\n",
        "model.add(InputLayer(input_shape=(input_neurons,)))\n",
        "model.add(Dense(units=1024,activation=\"tanh\"))\n",
        "model.add(Dense(units=512,activation=\"tanh\"))\n",
        "model.add(Dense(units=output_neurons,activation=\"sigmoid\"))\n",
        "model.summary()\n",
        "model.compile(loss=\"binary_crossentropy\",optimizer=\"Adam\",metrics=[\"accuracy\"])\n",
        "model_history=model.fit(xtrain,ytrain,validation_data=(xtest,ytest),epochs=20)\n",
        "prediction=model.predict(xtest)\n",
        "prediction=prediction.reshape(123,)\n",
        "prediction_int=prediction>=0.5\n",
        "prediction_int=prediction_int.astype(np.int)\n",
        "print(accuracy_score(ytest,prediction_int))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GsjhULbsIvzF",
        "outputId": "8979b0ed-5e53-443b-eca4-269ec85bbb9b"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_35 (Dense)            (None, 1024)              12288     \n",
            "                                                                 \n",
            " dense_36 (Dense)            (None, 512)               524800    \n",
            "                                                                 \n",
            " dense_37 (Dense)            (None, 1)                 513       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 537,601\n",
            "Trainable params: 537,601\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "16/16 [==============================] - 2s 48ms/step - loss: 0.6218 - accuracy: 0.7149 - val_loss: 0.5665 - val_accuracy: 0.7967\n",
            "Epoch 2/20\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.5055 - accuracy: 0.8065 - val_loss: 0.5010 - val_accuracy: 0.8130\n",
            "Epoch 3/20\n",
            "16/16 [==============================] - 0s 25ms/step - loss: 0.5034 - accuracy: 0.8024 - val_loss: 0.4905 - val_accuracy: 0.8130\n",
            "Epoch 4/20\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.4983 - accuracy: 0.8065 - val_loss: 0.4903 - val_accuracy: 0.8130\n",
            "Epoch 5/20\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.4842 - accuracy: 0.8106 - val_loss: 0.5013 - val_accuracy: 0.8130\n",
            "Epoch 6/20\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.4914 - accuracy: 0.8106 - val_loss: 0.4954 - val_accuracy: 0.8211\n",
            "Epoch 7/20\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 0.4829 - accuracy: 0.8065 - val_loss: 0.4833 - val_accuracy: 0.8130\n",
            "Epoch 8/20\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.4839 - accuracy: 0.8086 - val_loss: 0.4888 - val_accuracy: 0.8130\n",
            "Epoch 9/20\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.4826 - accuracy: 0.8106 - val_loss: 0.4871 - val_accuracy: 0.8130\n",
            "Epoch 10/20\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.4883 - accuracy: 0.8147 - val_loss: 0.4835 - val_accuracy: 0.8130\n",
            "Epoch 11/20\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.4829 - accuracy: 0.8086 - val_loss: 0.4846 - val_accuracy: 0.8130\n",
            "Epoch 12/20\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.4818 - accuracy: 0.8106 - val_loss: 0.4955 - val_accuracy: 0.8130\n",
            "Epoch 13/20\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.4938 - accuracy: 0.8106 - val_loss: 0.4821 - val_accuracy: 0.8130\n",
            "Epoch 14/20\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.4866 - accuracy: 0.8106 - val_loss: 0.5201 - val_accuracy: 0.7967\n",
            "Epoch 15/20\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.4940 - accuracy: 0.8086 - val_loss: 0.5138 - val_accuracy: 0.8130\n",
            "Epoch 16/20\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.4864 - accuracy: 0.8126 - val_loss: 0.4840 - val_accuracy: 0.8130\n",
            "Epoch 17/20\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.4823 - accuracy: 0.8106 - val_loss: 0.4810 - val_accuracy: 0.8130\n",
            "Epoch 18/20\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.4771 - accuracy: 0.8086 - val_loss: 0.4821 - val_accuracy: 0.8130\n",
            "Epoch 19/20\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.4785 - accuracy: 0.8106 - val_loss: 0.4825 - val_accuracy: 0.8130\n",
            "Epoch 20/20\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 0.4838 - accuracy: 0.8065 - val_loss: 0.4862 - val_accuracy: 0.8130\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "0.8130081300813008\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-55-47e6b07e8c20>:16: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  prediction_int=prediction_int.astype(np.int)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# increasing hidden layers\n",
        "\n",
        "\n",
        "\n",
        "model=Sequential()\n",
        "model.add(InputLayer(input_shape=(input_neurons,)))\n",
        "model.add(Dense(units=1000,activation=\"tanh\"))\n",
        "model.add(Dense(units=100,activation=\"tanh\"))\n",
        "model.add(Dense(units=neuron_hidden_layer_1,activation=\"tanh\"))\n",
        "model.add(Dense(units=neuron_hidden_layer_2,activation=\"tanh\"))\n",
        "model.add(Dense(units=output_neurons,activation=\"sigmoid\"))\n",
        "model.summary()\n",
        "model.compile(loss=\"binary_crossentropy\",optimizer=\"Adam\",metrics=[\"accuracy\"])\n",
        "model_history=model.fit(xtrain,ytrain,validation_data=(xtest,ytest),epochs=20)\n",
        "prediction=model.predict(xtest)\n",
        "prediction=prediction.reshape(123,)\n",
        "prediction_int=prediction>=0.5\n",
        "prediction_int=prediction_int.astype(np.int)\n",
        "print(accuracy_score(ytest,prediction_int))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kGgL7PYOIv0-",
        "outputId": "9bc5d451-203d-41c3-ea7b-1aea6a66ad97"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_48 (Dense)            (None, 1000)              12000     \n",
            "                                                                 \n",
            " dense_49 (Dense)            (None, 100)               100100    \n",
            "                                                                 \n",
            " dense_50 (Dense)            (None, 10)                1010      \n",
            "                                                                 \n",
            " dense_51 (Dense)            (None, 5)                 55        \n",
            "                                                                 \n",
            " dense_52 (Dense)            (None, 1)                 6         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 113,171\n",
            "Trainable params: 113,171\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "16/16 [==============================] - 1s 19ms/step - loss: 0.5817 - accuracy: 0.7658 - val_loss: 0.4960 - val_accuracy: 0.8130\n",
            "Epoch 2/20\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.4892 - accuracy: 0.8086 - val_loss: 0.4784 - val_accuracy: 0.8130\n",
            "Epoch 3/20\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.4807 - accuracy: 0.8086 - val_loss: 0.4743 - val_accuracy: 0.8130\n",
            "Epoch 4/20\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.4775 - accuracy: 0.8086 - val_loss: 0.4766 - val_accuracy: 0.8130\n",
            "Epoch 5/20\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.4745 - accuracy: 0.8086 - val_loss: 0.4738 - val_accuracy: 0.8130\n",
            "Epoch 6/20\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.4706 - accuracy: 0.8106 - val_loss: 0.4791 - val_accuracy: 0.8130\n",
            "Epoch 7/20\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.4715 - accuracy: 0.8086 - val_loss: 0.4842 - val_accuracy: 0.8049\n",
            "Epoch 8/20\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.4730 - accuracy: 0.8106 - val_loss: 0.4797 - val_accuracy: 0.8130\n",
            "Epoch 9/20\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.4703 - accuracy: 0.8106 - val_loss: 0.4749 - val_accuracy: 0.8049\n",
            "Epoch 10/20\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4651 - accuracy: 0.8147 - val_loss: 0.4802 - val_accuracy: 0.8049\n",
            "Epoch 11/20\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4610 - accuracy: 0.8147 - val_loss: 0.4849 - val_accuracy: 0.8049\n",
            "Epoch 12/20\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.4610 - accuracy: 0.8147 - val_loss: 0.4816 - val_accuracy: 0.8049\n",
            "Epoch 13/20\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.4635 - accuracy: 0.8126 - val_loss: 0.4830 - val_accuracy: 0.8049\n",
            "Epoch 14/20\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4590 - accuracy: 0.8147 - val_loss: 0.4939 - val_accuracy: 0.8049\n",
            "Epoch 15/20\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.4551 - accuracy: 0.8147 - val_loss: 0.4833 - val_accuracy: 0.8049\n",
            "Epoch 16/20\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.4563 - accuracy: 0.8147 - val_loss: 0.4980 - val_accuracy: 0.8049\n",
            "Epoch 17/20\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4556 - accuracy: 0.8147 - val_loss: 0.4965 - val_accuracy: 0.8049\n",
            "Epoch 18/20\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.4532 - accuracy: 0.8167 - val_loss: 0.4897 - val_accuracy: 0.7967\n",
            "Epoch 19/20\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4696 - accuracy: 0.8086 - val_loss: 0.5043 - val_accuracy: 0.8049\n",
            "Epoch 20/20\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4575 - accuracy: 0.8126 - val_loss: 0.4932 - val_accuracy: 0.8130\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "0.8130081300813008\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-58-b0a1df52f9d4>:18: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  prediction_int=prediction_int.astype(np.int)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# increasing no. of epochs\n",
        "\n",
        "\n",
        "\n",
        "model=Sequential()\n",
        "model.add(InputLayer(input_shape=(input_neurons,)))\n",
        "model.add(Dense(units=neuron_hidden_layer_1,activation=\"tanh\"))\n",
        "model.add(Dense(units=neuron_hidden_layer_2,activation=\"tanh\"))\n",
        "model.add(Dense(units=output_neurons,activation=\"sigmoid\"))\n",
        "model.summary()\n",
        "model.compile(loss=\"binary_crossentropy\",optimizer=\"Adam\",metrics=[\"accuracy\"])\n",
        "model_history=model.fit(xtrain,ytrain,validation_data=(xtest,ytest),epochs=100)\n",
        "prediction=model.predict(xtest)\n",
        "prediction=prediction.reshape(123,)\n",
        "prediction_int=prediction>=0.5\n",
        "prediction_int=prediction_int.astype(np.int)\n",
        "print(accuracy_score(ytest,prediction_int))\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F3vOEMQ2Iv4Y",
        "outputId": "6f4790d9-337e-4181-b48f-82e422208d7e"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_53 (Dense)            (None, 10)                120       \n",
            "                                                                 \n",
            " dense_54 (Dense)            (None, 5)                 55        \n",
            "                                                                 \n",
            " dense_55 (Dense)            (None, 1)                 6         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 181\n",
            "Trainable params: 181\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 29ms/step - loss: 0.5869 - accuracy: 0.7210 - val_loss: 0.5908 - val_accuracy: 0.7236\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.5787 - accuracy: 0.7210 - val_loss: 0.5833 - val_accuracy: 0.7236\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.5702 - accuracy: 0.7271 - val_loss: 0.5763 - val_accuracy: 0.7236\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.5628 - accuracy: 0.7312 - val_loss: 0.5702 - val_accuracy: 0.7398\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.5549 - accuracy: 0.7393 - val_loss: 0.5635 - val_accuracy: 0.7561\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.5495 - accuracy: 0.7434 - val_loss: 0.5568 - val_accuracy: 0.7561\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.5423 - accuracy: 0.7637 - val_loss: 0.5509 - val_accuracy: 0.7724\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.5361 - accuracy: 0.7800 - val_loss: 0.5449 - val_accuracy: 0.7724\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.5308 - accuracy: 0.7902 - val_loss: 0.5395 - val_accuracy: 0.7724\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.5258 - accuracy: 0.7943 - val_loss: 0.5348 - val_accuracy: 0.7967\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.5204 - accuracy: 0.8004 - val_loss: 0.5302 - val_accuracy: 0.7967\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.5160 - accuracy: 0.8004 - val_loss: 0.5264 - val_accuracy: 0.7967\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.5123 - accuracy: 0.8024 - val_loss: 0.5222 - val_accuracy: 0.8049\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.5084 - accuracy: 0.8065 - val_loss: 0.5187 - val_accuracy: 0.8049\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.5047 - accuracy: 0.8086 - val_loss: 0.5143 - val_accuracy: 0.8049\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.5017 - accuracy: 0.8086 - val_loss: 0.5109 - val_accuracy: 0.8130\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.4988 - accuracy: 0.8086 - val_loss: 0.5083 - val_accuracy: 0.8130\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.4956 - accuracy: 0.8086 - val_loss: 0.5059 - val_accuracy: 0.8130\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4933 - accuracy: 0.8086 - val_loss: 0.5030 - val_accuracy: 0.8130\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4916 - accuracy: 0.8086 - val_loss: 0.5012 - val_accuracy: 0.8130\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.4889 - accuracy: 0.8086 - val_loss: 0.4987 - val_accuracy: 0.8130\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.4871 - accuracy: 0.8086 - val_loss: 0.4972 - val_accuracy: 0.8130\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4865 - accuracy: 0.8086 - val_loss: 0.4963 - val_accuracy: 0.8130\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4842 - accuracy: 0.8086 - val_loss: 0.4940 - val_accuracy: 0.8130\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4825 - accuracy: 0.8086 - val_loss: 0.4927 - val_accuracy: 0.8130\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.4814 - accuracy: 0.8086 - val_loss: 0.4914 - val_accuracy: 0.8130\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4797 - accuracy: 0.8106 - val_loss: 0.4903 - val_accuracy: 0.8130\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4787 - accuracy: 0.8106 - val_loss: 0.4888 - val_accuracy: 0.8130\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.4779 - accuracy: 0.8106 - val_loss: 0.4874 - val_accuracy: 0.8130\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.4773 - accuracy: 0.8106 - val_loss: 0.4865 - val_accuracy: 0.8130\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4759 - accuracy: 0.8106 - val_loss: 0.4856 - val_accuracy: 0.8130\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.4745 - accuracy: 0.8106 - val_loss: 0.4852 - val_accuracy: 0.8130\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4739 - accuracy: 0.8126 - val_loss: 0.4843 - val_accuracy: 0.8130\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4733 - accuracy: 0.8126 - val_loss: 0.4829 - val_accuracy: 0.8130\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4724 - accuracy: 0.8126 - val_loss: 0.4832 - val_accuracy: 0.8130\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4715 - accuracy: 0.8126 - val_loss: 0.4821 - val_accuracy: 0.8130\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4709 - accuracy: 0.8126 - val_loss: 0.4820 - val_accuracy: 0.8130\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4700 - accuracy: 0.8126 - val_loss: 0.4815 - val_accuracy: 0.8130\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.4698 - accuracy: 0.8126 - val_loss: 0.4811 - val_accuracy: 0.8130\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.4697 - accuracy: 0.8126 - val_loss: 0.4808 - val_accuracy: 0.8130\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.4684 - accuracy: 0.8126 - val_loss: 0.4808 - val_accuracy: 0.8130\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.4687 - accuracy: 0.8126 - val_loss: 0.4807 - val_accuracy: 0.8130\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.4680 - accuracy: 0.8126 - val_loss: 0.4798 - val_accuracy: 0.8130\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.4672 - accuracy: 0.8126 - val_loss: 0.4799 - val_accuracy: 0.8130\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4668 - accuracy: 0.8126 - val_loss: 0.4795 - val_accuracy: 0.8130\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4670 - accuracy: 0.8126 - val_loss: 0.4800 - val_accuracy: 0.8130\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4677 - accuracy: 0.8126 - val_loss: 0.4798 - val_accuracy: 0.8130\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4657 - accuracy: 0.8126 - val_loss: 0.4798 - val_accuracy: 0.8130\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4657 - accuracy: 0.8126 - val_loss: 0.4794 - val_accuracy: 0.8130\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.4652 - accuracy: 0.8126 - val_loss: 0.4791 - val_accuracy: 0.8130\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.8126 - val_loss: 0.4793 - val_accuracy: 0.8130\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.4651 - accuracy: 0.8126 - val_loss: 0.4787 - val_accuracy: 0.8130\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.4655 - accuracy: 0.8126 - val_loss: 0.4788 - val_accuracy: 0.8130\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4642 - accuracy: 0.8126 - val_loss: 0.4783 - val_accuracy: 0.8130\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4640 - accuracy: 0.8126 - val_loss: 0.4788 - val_accuracy: 0.8130\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4638 - accuracy: 0.8126 - val_loss: 0.4784 - val_accuracy: 0.8130\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.4636 - accuracy: 0.8126 - val_loss: 0.4782 - val_accuracy: 0.8130\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4634 - accuracy: 0.8126 - val_loss: 0.4783 - val_accuracy: 0.8130\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4654 - accuracy: 0.8126 - val_loss: 0.4777 - val_accuracy: 0.8130\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4628 - accuracy: 0.8126 - val_loss: 0.4784 - val_accuracy: 0.8130\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4639 - accuracy: 0.8126 - val_loss: 0.4781 - val_accuracy: 0.8130\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.4626 - accuracy: 0.8126 - val_loss: 0.4787 - val_accuracy: 0.8130\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.4644 - accuracy: 0.8126 - val_loss: 0.4777 - val_accuracy: 0.8130\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4628 - accuracy: 0.8126 - val_loss: 0.4797 - val_accuracy: 0.8130\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.4628 - accuracy: 0.8126 - val_loss: 0.4785 - val_accuracy: 0.8130\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4622 - accuracy: 0.8126 - val_loss: 0.4787 - val_accuracy: 0.8130\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4623 - accuracy: 0.8126 - val_loss: 0.4783 - val_accuracy: 0.8130\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.4627 - accuracy: 0.8126 - val_loss: 0.4782 - val_accuracy: 0.8130\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.4630 - accuracy: 0.8126 - val_loss: 0.4789 - val_accuracy: 0.8130\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.4618 - accuracy: 0.8106 - val_loss: 0.4787 - val_accuracy: 0.8130\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4612 - accuracy: 0.8126 - val_loss: 0.4784 - val_accuracy: 0.8130\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4619 - accuracy: 0.8126 - val_loss: 0.4787 - val_accuracy: 0.8130\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.4613 - accuracy: 0.8126 - val_loss: 0.4786 - val_accuracy: 0.8130\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4618 - accuracy: 0.8126 - val_loss: 0.4789 - val_accuracy: 0.8130\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.4616 - accuracy: 0.8126 - val_loss: 0.4785 - val_accuracy: 0.8130\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4612 - accuracy: 0.8126 - val_loss: 0.4794 - val_accuracy: 0.8130\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4614 - accuracy: 0.8106 - val_loss: 0.4796 - val_accuracy: 0.8130\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4615 - accuracy: 0.8126 - val_loss: 0.4791 - val_accuracy: 0.8130\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4609 - accuracy: 0.8126 - val_loss: 0.4794 - val_accuracy: 0.8130\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4605 - accuracy: 0.8126 - val_loss: 0.4802 - val_accuracy: 0.8130\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.4609 - accuracy: 0.8106 - val_loss: 0.4805 - val_accuracy: 0.8130\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4606 - accuracy: 0.8106 - val_loss: 0.4801 - val_accuracy: 0.8130\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4603 - accuracy: 0.8106 - val_loss: 0.4801 - val_accuracy: 0.8130\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.4605 - accuracy: 0.8126 - val_loss: 0.4798 - val_accuracy: 0.8130\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4602 - accuracy: 0.8126 - val_loss: 0.4800 - val_accuracy: 0.8130\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.4606 - accuracy: 0.8106 - val_loss: 0.4813 - val_accuracy: 0.8130\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4600 - accuracy: 0.8126 - val_loss: 0.4804 - val_accuracy: 0.8130\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4605 - accuracy: 0.8126 - val_loss: 0.4808 - val_accuracy: 0.8130\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.4595 - accuracy: 0.8126 - val_loss: 0.4809 - val_accuracy: 0.8130\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.4598 - accuracy: 0.8126 - val_loss: 0.4812 - val_accuracy: 0.8130\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.4601 - accuracy: 0.8106 - val_loss: 0.4824 - val_accuracy: 0.8130\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4593 - accuracy: 0.8126 - val_loss: 0.4814 - val_accuracy: 0.8130\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.4599 - accuracy: 0.8126 - val_loss: 0.4814 - val_accuracy: 0.8130\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.4597 - accuracy: 0.8126 - val_loss: 0.4810 - val_accuracy: 0.8130\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4592 - accuracy: 0.8106 - val_loss: 0.4818 - val_accuracy: 0.8130\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.4607 - accuracy: 0.8126 - val_loss: 0.4815 - val_accuracy: 0.8130\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4592 - accuracy: 0.8126 - val_loss: 0.4821 - val_accuracy: 0.8130\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.4589 - accuracy: 0.8126 - val_loss: 0.4824 - val_accuracy: 0.8130\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4585 - accuracy: 0.8126 - val_loss: 0.4820 - val_accuracy: 0.8130\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.4591 - accuracy: 0.8126 - val_loss: 0.4821 - val_accuracy: 0.8130\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "0.8130081300813008\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-59-0f9627c3c7b6>:16: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  prediction_int=prediction_int.astype(np.int)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# changing optimizer\n",
        "\n",
        "from keras.optimizers import Adam\n",
        "adam=Adam(lr=1e-5)\n",
        "\n",
        "\n",
        "model=Sequential()\n",
        "model.add(InputLayer(input_shape=(input_neurons,)))\n",
        "model.add(Dense(units=neuron_hidden_layer_1,activation=\"tanh\"))\n",
        "model.add(Dense(units=neuron_hidden_layer_2,activation=\"tanh\"))\n",
        "model.add(Dense(units=output_neurons,activation=\"sigmoid\"))\n",
        "model.summary()\n",
        "model.compile(loss=\"binary_crossentropy\",optimizer=\"adam\",metrics=[\"accuracy\"])\n",
        "model_history=model.fit(xtrain,ytrain,validation_data=(xtest,ytest),epochs=20)\n",
        "prediction=model.predict(xtest)\n",
        "prediction=prediction.reshape(123,)\n",
        "prediction_int=prediction>=0.5\n",
        "prediction_int=prediction_int.astype(np.int)\n",
        "print(accuracy_score(ytest,prediction_int))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zz4NoHKxIv5-",
        "outputId": "272081f1-52fa-4b19-b806-9c83b37e0e58"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_59 (Dense)            (None, 10)                120       \n",
            "                                                                 \n",
            " dense_60 (Dense)            (None, 5)                 55        \n",
            "                                                                 \n",
            " dense_61 (Dense)            (None, 1)                 6         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 181\n",
            "Trainable params: 181\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "16/16 [==============================] - 1s 15ms/step - loss: 0.6330 - accuracy: 0.6578 - val_loss: 0.6305 - val_accuracy: 0.6748\n",
            "Epoch 2/20\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6204 - accuracy: 0.6823 - val_loss: 0.6204 - val_accuracy: 0.6829\n",
            "Epoch 3/20\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6120 - accuracy: 0.6823 - val_loss: 0.6122 - val_accuracy: 0.6911\n",
            "Epoch 4/20\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6041 - accuracy: 0.6884 - val_loss: 0.6051 - val_accuracy: 0.6911\n",
            "Epoch 5/20\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.5975 - accuracy: 0.6945 - val_loss: 0.5988 - val_accuracy: 0.6911\n",
            "Epoch 6/20\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.5907 - accuracy: 0.6965 - val_loss: 0.5928 - val_accuracy: 0.6911\n",
            "Epoch 7/20\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.5851 - accuracy: 0.6986 - val_loss: 0.5862 - val_accuracy: 0.6911\n",
            "Epoch 8/20\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.5789 - accuracy: 0.7026 - val_loss: 0.5812 - val_accuracy: 0.7073\n",
            "Epoch 9/20\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.5732 - accuracy: 0.7067 - val_loss: 0.5746 - val_accuracy: 0.7073\n",
            "Epoch 10/20\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.5673 - accuracy: 0.7169 - val_loss: 0.5680 - val_accuracy: 0.6992\n",
            "Epoch 11/20\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.5609 - accuracy: 0.7210 - val_loss: 0.5627 - val_accuracy: 0.7154\n",
            "Epoch 12/20\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.5549 - accuracy: 0.7332 - val_loss: 0.5570 - val_accuracy: 0.7154\n",
            "Epoch 13/20\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.5493 - accuracy: 0.7413 - val_loss: 0.5509 - val_accuracy: 0.7398\n",
            "Epoch 14/20\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.5432 - accuracy: 0.7576 - val_loss: 0.5445 - val_accuracy: 0.7561\n",
            "Epoch 15/20\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.5377 - accuracy: 0.7637 - val_loss: 0.5388 - val_accuracy: 0.7886\n",
            "Epoch 16/20\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.5326 - accuracy: 0.8004 - val_loss: 0.5341 - val_accuracy: 0.8049\n",
            "Epoch 17/20\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.5267 - accuracy: 0.8065 - val_loss: 0.5285 - val_accuracy: 0.8049\n",
            "Epoch 18/20\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.5214 - accuracy: 0.8065 - val_loss: 0.5241 - val_accuracy: 0.8130\n",
            "Epoch 19/20\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.5175 - accuracy: 0.8086 - val_loss: 0.5190 - val_accuracy: 0.8130\n",
            "Epoch 20/20\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.5118 - accuracy: 0.8086 - val_loss: 0.5148 - val_accuracy: 0.8130\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "0.8130081300813008\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-62-b7b6d6c4b9ed>:18: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  prediction_int=prediction_int.astype(np.int)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Improving Deep Learning model--\n",
        "\n",
        "'''\n",
        "1. Early stopping \n",
        "2. Dropout\n",
        "3. Vanishing and Exploding Gradients\n",
        "4. Various weight inintializing technique\n",
        "5. BatchNormalization\n",
        "'''"
      ],
      "metadata": {
        "id": "vs5RITo5Iv82"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. EarlyStopping\n",
        "\n",
        "\n",
        "\n",
        "model=Sequential()\n",
        "model.add(InputLayer(input_shape=(input_neurons,)))\n",
        "model.add(Dense(units=neuron_hidden_layer_1,activation=\"tanh\"))\n",
        "model.add(Dense(units=neuron_hidden_layer_2,activation=\"tanh\"))\n",
        "model.add(Dense(units=output_neurons,activation=\"sigmoid\"))\n",
        "model.summary()\n",
        "model.compile(loss=\"binary_crossentropy\",optimizer=\"Adam\",metrics=[\"accuracy\"])\n",
        "\n",
        "from keras.callbacks import EarlyStopping\n",
        "es=EarlyStopping(monitor=\"val_loss\",min_delta=0.01,patience=5,mode=\"min\")\n",
        "model_history=model.fit(xtrain,ytrain,validation_data=(xtest,ytest),epochs=100,callbacks=[es])\n",
        "prediction=model.predict(xtest)\n",
        "prediction=prediction.reshape(123,)\n",
        "prediction_int=prediction>=0.5\n",
        "prediction_int=prediction_int.astype(np.int)\n",
        "print(accuracy_score(ytest,prediction_int))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fs0p71WNIv_3",
        "outputId": "979737c8-75dd-4805-a915-41b1f2b1ec70"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_15\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_62 (Dense)            (None, 10)                120       \n",
            "                                                                 \n",
            " dense_63 (Dense)            (None, 5)                 55        \n",
            "                                                                 \n",
            " dense_64 (Dense)            (None, 1)                 6         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 181\n",
            "Trainable params: 181\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 16ms/step - loss: 0.7544 - accuracy: 0.3360 - val_loss: 0.7174 - val_accuracy: 0.4390\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6921 - accuracy: 0.5214 - val_loss: 0.6682 - val_accuracy: 0.6179\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6514 - accuracy: 0.6538 - val_loss: 0.6392 - val_accuracy: 0.7073\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6292 - accuracy: 0.6884 - val_loss: 0.6218 - val_accuracy: 0.6992\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6179 - accuracy: 0.6864 - val_loss: 0.6117 - val_accuracy: 0.6911\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6106 - accuracy: 0.6864 - val_loss: 0.6067 - val_accuracy: 0.6911\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.6061 - accuracy: 0.6864 - val_loss: 0.6030 - val_accuracy: 0.6911\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6019 - accuracy: 0.6864 - val_loss: 0.5994 - val_accuracy: 0.6911\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.5978 - accuracy: 0.6864 - val_loss: 0.5957 - val_accuracy: 0.6911\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.5933 - accuracy: 0.6864 - val_loss: 0.5912 - val_accuracy: 0.6911\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.5882 - accuracy: 0.6864 - val_loss: 0.5866 - val_accuracy: 0.6911\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.5829 - accuracy: 0.6864 - val_loss: 0.5816 - val_accuracy: 0.6911\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.5777 - accuracy: 0.6884 - val_loss: 0.5763 - val_accuracy: 0.6911\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.5709 - accuracy: 0.6904 - val_loss: 0.5705 - val_accuracy: 0.6911\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.5646 - accuracy: 0.6925 - val_loss: 0.5647 - val_accuracy: 0.7073\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.5576 - accuracy: 0.7026 - val_loss: 0.5584 - val_accuracy: 0.7073\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.5510 - accuracy: 0.7332 - val_loss: 0.5524 - val_accuracy: 0.7236\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.5444 - accuracy: 0.7454 - val_loss: 0.5461 - val_accuracy: 0.7398\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.5383 - accuracy: 0.7739 - val_loss: 0.5397 - val_accuracy: 0.7642\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.5321 - accuracy: 0.7923 - val_loss: 0.5346 - val_accuracy: 0.7886\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.5265 - accuracy: 0.8024 - val_loss: 0.5299 - val_accuracy: 0.7886\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.5212 - accuracy: 0.8045 - val_loss: 0.5247 - val_accuracy: 0.8049\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.5164 - accuracy: 0.8086 - val_loss: 0.5201 - val_accuracy: 0.8049\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.5120 - accuracy: 0.8106 - val_loss: 0.5160 - val_accuracy: 0.8130\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.5072 - accuracy: 0.8106 - val_loss: 0.5128 - val_accuracy: 0.8130\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.5046 - accuracy: 0.8106 - val_loss: 0.5094 - val_accuracy: 0.8130\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.5012 - accuracy: 0.8126 - val_loss: 0.5074 - val_accuracy: 0.8130\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4979 - accuracy: 0.8106 - val_loss: 0.5046 - val_accuracy: 0.8130\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4948 - accuracy: 0.8106 - val_loss: 0.5029 - val_accuracy: 0.8130\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.4926 - accuracy: 0.8126 - val_loss: 0.5006 - val_accuracy: 0.8130\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.4907 - accuracy: 0.8126 - val_loss: 0.4989 - val_accuracy: 0.8130\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4883 - accuracy: 0.8126 - val_loss: 0.4971 - val_accuracy: 0.8130\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4859 - accuracy: 0.8126 - val_loss: 0.4955 - val_accuracy: 0.8130\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.4843 - accuracy: 0.8126 - val_loss: 0.4943 - val_accuracy: 0.8130\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4821 - accuracy: 0.8126 - val_loss: 0.4932 - val_accuracy: 0.8130\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "0.8130081300813008\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-63-f41700772276>:19: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  prediction_int=prediction_int.astype(np.int)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dropout\n",
        "\n",
        "'''\n",
        "Dropout technique\n",
        "This is one of the most interesting types of regularization techniques. It also\n",
        "produces very good results and is consequently the most frequently used\n",
        "regularization technique in the field of deep learning.\n",
        "\n",
        "At every iteration, the dropout technique randomly selects some nodes and\n",
        "removes them along with all of their incoming and outgoing connections as\n",
        "shown below\n",
        "\n",
        "The above code shows the probability (0.50) of choosing how many nodes should\n",
        "be dropped is the hyperparameter of the dropout layer\n",
        "'''\n",
        "\n",
        "\n",
        "\n",
        "from keras.layers import Dropout\n",
        "\n",
        "\n",
        "\n",
        "model=Sequential()\n",
        "model.add(InputLayer(input_shape=(input_neurons,)))\n",
        "model.add(Dense(units=100,activation=\"tanh\"))\n",
        "model.add(Dropout(rate=0.5))\n",
        "model.add(Dense(units=100,activation=\"tanh\"))\n",
        "model.add(Dropout(rate=0.5))\n",
        "model.add(Dense(units=output_neurons,activation=\"sigmoid\"))\n",
        "model.summary()\n",
        "model.compile(loss=\"binary_crossentropy\",optimizer=\"Adam\",metrics=[\"accuracy\"])\n",
        "model_history=model.fit(xtrain,ytrain,validation_data=(xtest,ytest),epochs=20)\n",
        "prediction=model.predict(xtest)\n",
        "prediction=prediction.reshape(123,)\n",
        "prediction_int=prediction>=0.5\n",
        "prediction_int=prediction_int.astype(np.int)\n",
        "print(accuracy_score(ytest,prediction_int))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UN5r3cHKIwBs",
        "outputId": "623b95a0-9806-4962-e524-7006631a15ac"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_65 (Dense)            (None, 100)               1200      \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 100)               0         \n",
            "                                                                 \n",
            " dense_66 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " dense_67 (Dense)            (None, 1)                 101       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 11,401\n",
            "Trainable params: 11,401\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "16/16 [==============================] - 1s 17ms/step - loss: 0.6254 - accuracy: 0.6660 - val_loss: 0.5664 - val_accuracy: 0.6911\n",
            "Epoch 2/20\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.5780 - accuracy: 0.7067 - val_loss: 0.5359 - val_accuracy: 0.7480\n",
            "Epoch 3/20\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.5427 - accuracy: 0.7658 - val_loss: 0.5205 - val_accuracy: 0.7967\n",
            "Epoch 4/20\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.5351 - accuracy: 0.7821 - val_loss: 0.5079 - val_accuracy: 0.8130\n",
            "Epoch 5/20\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.5258 - accuracy: 0.7760 - val_loss: 0.5014 - val_accuracy: 0.8130\n",
            "Epoch 6/20\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.5284 - accuracy: 0.7923 - val_loss: 0.4953 - val_accuracy: 0.8130\n",
            "Epoch 7/20\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.5153 - accuracy: 0.7984 - val_loss: 0.4949 - val_accuracy: 0.8130\n",
            "Epoch 8/20\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4966 - accuracy: 0.8065 - val_loss: 0.4927 - val_accuracy: 0.8130\n",
            "Epoch 9/20\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4850 - accuracy: 0.8045 - val_loss: 0.4936 - val_accuracy: 0.8130\n",
            "Epoch 10/20\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4960 - accuracy: 0.8065 - val_loss: 0.4924 - val_accuracy: 0.8130\n",
            "Epoch 11/20\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.5189 - accuracy: 0.8004 - val_loss: 0.4900 - val_accuracy: 0.8130\n",
            "Epoch 12/20\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.5030 - accuracy: 0.8065 - val_loss: 0.4905 - val_accuracy: 0.8130\n",
            "Epoch 13/20\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4920 - accuracy: 0.8086 - val_loss: 0.4877 - val_accuracy: 0.8130\n",
            "Epoch 14/20\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.5112 - accuracy: 0.8004 - val_loss: 0.4866 - val_accuracy: 0.8130\n",
            "Epoch 15/20\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4936 - accuracy: 0.7984 - val_loss: 0.4845 - val_accuracy: 0.8130\n",
            "Epoch 16/20\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4813 - accuracy: 0.8086 - val_loss: 0.4832 - val_accuracy: 0.8130\n",
            "Epoch 17/20\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.5015 - accuracy: 0.8045 - val_loss: 0.4859 - val_accuracy: 0.8130\n",
            "Epoch 18/20\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.4936 - accuracy: 0.7984 - val_loss: 0.4881 - val_accuracy: 0.8130\n",
            "Epoch 19/20\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.5070 - accuracy: 0.8024 - val_loss: 0.4870 - val_accuracy: 0.8130\n",
            "Epoch 20/20\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.5279 - accuracy: 0.7984 - val_loss: 0.4894 - val_accuracy: 0.8130\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "0.8130081300813008\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-64-8213d952981e>:20: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  prediction_int=prediction_int.astype(np.int)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# vanishing and exploding gradients\n",
        "\n",
        "\n",
        "\n",
        "model=Sequential()\n",
        "model.add(InputLayer(input_shape=(input_neurons,)))\n",
        "model.add(Dense(units=100,activation=\"tanh\"))\n",
        "model.add(Dropout(rate=0.05))\n",
        "model.add(Dense(units=100,activation=\"tanh\"))\n",
        "model.add(Dropout(0.05))\n",
        "model.add(Dense(units=output_neurons,activation=\"sigmoid\"))\n",
        "model.summary()\n",
        "adam=Adam(lr=1e-5,clipvalue=1)\n",
        "#clipvalue clips the gradient value at the backpropogation.\n",
        "# any value<-1 will be made -1 and >1 will be 1\n",
        "model.compile(loss=\"binary_crossentropy\",optimizer=adam,metrics=[\"accuracy\"])\n",
        "model_history=model.fit(xtrain,ytrain,validation_data=(xtest,ytest),epochs=20)\n",
        "prediction=model.predict(xtest)\n",
        "prediction=prediction.reshape(123,)\n",
        "prediction_int=prediction>=0.5\n",
        "prediction_int=prediction_int.astype(np.int)\n",
        "print(accuracy_score(ytest,prediction_int))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OsCjDgb0IwDg",
        "outputId": "48216cee-268c-4425-fb3b-b7a495ba1296"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_18\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_71 (Dense)            (None, 100)               1200      \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " dense_72 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " dense_73 (Dense)            (None, 1)                 101       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 11,401\n",
            "Trainable params: 11,401\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "16/16 [==============================] - 1s 17ms/step - loss: 0.6835 - accuracy: 0.5275 - val_loss: 0.6749 - val_accuracy: 0.5610\n",
            "Epoch 2/20\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6777 - accuracy: 0.5662 - val_loss: 0.6661 - val_accuracy: 0.5854\n",
            "Epoch 3/20\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.6657 - accuracy: 0.6212 - val_loss: 0.6579 - val_accuracy: 0.6667\n",
            "Epoch 4/20\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.6596 - accuracy: 0.6395 - val_loss: 0.6513 - val_accuracy: 0.6911\n",
            "Epoch 5/20\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6510 - accuracy: 0.6864 - val_loss: 0.6444 - val_accuracy: 0.7480\n",
            "Epoch 6/20\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.6463 - accuracy: 0.6762 - val_loss: 0.6383 - val_accuracy: 0.7480\n",
            "Epoch 7/20\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.6412 - accuracy: 0.7026 - val_loss: 0.6321 - val_accuracy: 0.7642\n",
            "Epoch 8/20\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6359 - accuracy: 0.7189 - val_loss: 0.6268 - val_accuracy: 0.7642\n",
            "Epoch 9/20\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.6307 - accuracy: 0.7332 - val_loss: 0.6222 - val_accuracy: 0.7480\n",
            "Epoch 10/20\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.6271 - accuracy: 0.7352 - val_loss: 0.6177 - val_accuracy: 0.7480\n",
            "Epoch 11/20\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.6213 - accuracy: 0.7332 - val_loss: 0.6137 - val_accuracy: 0.7398\n",
            "Epoch 12/20\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6165 - accuracy: 0.7291 - val_loss: 0.6096 - val_accuracy: 0.7398\n",
            "Epoch 13/20\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6140 - accuracy: 0.7271 - val_loss: 0.6063 - val_accuracy: 0.7398\n",
            "Epoch 14/20\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6065 - accuracy: 0.7271 - val_loss: 0.6030 - val_accuracy: 0.7398\n",
            "Epoch 15/20\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.6093 - accuracy: 0.7108 - val_loss: 0.6003 - val_accuracy: 0.7317\n",
            "Epoch 16/20\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.6058 - accuracy: 0.7210 - val_loss: 0.5975 - val_accuracy: 0.7398\n",
            "Epoch 17/20\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6006 - accuracy: 0.7210 - val_loss: 0.5952 - val_accuracy: 0.7398\n",
            "Epoch 18/20\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.6021 - accuracy: 0.7108 - val_loss: 0.5928 - val_accuracy: 0.7398\n",
            "Epoch 19/20\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.5987 - accuracy: 0.7108 - val_loss: 0.5907 - val_accuracy: 0.7398\n",
            "Epoch 20/20\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.5959 - accuracy: 0.7088 - val_loss: 0.5884 - val_accuracy: 0.7317\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "0.7317073170731707\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-68-ee21245c9910>:19: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  prediction_int=prediction_int.astype(np.int)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Different weight initialization techniques like- Random Normal Initialization, Glorot/Xavier Normal Initialization, He Normal Initialization"
      ],
      "metadata": {
        "id": "whQsWFDDIwGL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.backend import random_normal\n",
        "\n",
        "from keras import initializers\n",
        "model=Sequential()\n",
        "model.add(InputLayer(input_shape=(input_neurons,)))\n",
        "ini=keras.initializers.RandomUniform(minval=0,maxval=1)\n",
        "model.add(Dense(units=100,activation=\"tanh\",kernel_initializer=ini))\n",
        "ini=keras.initializers.GlorotUniform()\n",
        "model.add(Dense(units=100,activation=\"tanh\",kernel_initializer=ini))\n",
        "ini=keras.initializers.HeUniform()\n",
        "model.add(Dense(units=100,activation=\"tanh\",kernel_initializer=ini))\n",
        "model.add(Dense(units=output_neurons,activation=\"sigmoid\",kernel_initializer=ini))\n",
        "model.summary()\n",
        "model.compile(loss=\"binary_crossentropy\",optimizer=\"Adam\",metrics=[\"accuracy\"])\n",
        "model_history=model.fit(xtrain,ytrain,validation_data=(xtest,ytest),epochs=20)\n",
        "prediction=model.predict(xtest)\n",
        "prediction=prediction.reshape(123,)\n",
        "prediction_int=prediction>=0.5\n",
        "prediction_int=prediction_int.astype(np.int)\n",
        "print(accuracy_score(ytest,prediction_int))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ENORdU8YIwHw",
        "outputId": "06091d3a-fadf-4f9f-f560-02ae013fbf0a"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_27\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_83 (Dense)            (None, 100)               1200      \n",
            "                                                                 \n",
            " dense_84 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_85 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_86 (Dense)            (None, 1)                 101       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 21,501\n",
            "Trainable params: 21,501\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "16/16 [==============================] - 1s 17ms/step - loss: 0.6772 - accuracy: 0.6497 - val_loss: 0.6277 - val_accuracy: 0.6911\n",
            "Epoch 2/20\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.6087 - accuracy: 0.6884 - val_loss: 0.6009 - val_accuracy: 0.6911\n",
            "Epoch 3/20\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.5983 - accuracy: 0.7006 - val_loss: 0.5887 - val_accuracy: 0.6911\n",
            "Epoch 4/20\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.5882 - accuracy: 0.7067 - val_loss: 0.5779 - val_accuracy: 0.7317\n",
            "Epoch 5/20\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.5784 - accuracy: 0.7210 - val_loss: 0.5582 - val_accuracy: 0.7317\n",
            "Epoch 6/20\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.5620 - accuracy: 0.7536 - val_loss: 0.5511 - val_accuracy: 0.7805\n",
            "Epoch 7/20\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.5695 - accuracy: 0.7352 - val_loss: 0.5927 - val_accuracy: 0.7154\n",
            "Epoch 8/20\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.5389 - accuracy: 0.7699 - val_loss: 0.5473 - val_accuracy: 0.7480\n",
            "Epoch 9/20\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.5373 - accuracy: 0.7719 - val_loss: 0.5174 - val_accuracy: 0.7805\n",
            "Epoch 10/20\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.5235 - accuracy: 0.7739 - val_loss: 0.5070 - val_accuracy: 0.7886\n",
            "Epoch 11/20\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.5004 - accuracy: 0.7943 - val_loss: 0.5013 - val_accuracy: 0.7886\n",
            "Epoch 12/20\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.5155 - accuracy: 0.7902 - val_loss: 0.5166 - val_accuracy: 0.7886\n",
            "Epoch 13/20\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.5073 - accuracy: 0.7923 - val_loss: 0.5052 - val_accuracy: 0.8049\n",
            "Epoch 14/20\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4969 - accuracy: 0.8045 - val_loss: 0.4968 - val_accuracy: 0.7967\n",
            "Epoch 15/20\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4938 - accuracy: 0.8086 - val_loss: 0.5475 - val_accuracy: 0.7886\n",
            "Epoch 16/20\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.5268 - accuracy: 0.7984 - val_loss: 0.4909 - val_accuracy: 0.8049\n",
            "Epoch 17/20\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.5080 - accuracy: 0.8024 - val_loss: 0.5331 - val_accuracy: 0.8130\n",
            "Epoch 18/20\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.5403 - accuracy: 0.8045 - val_loss: 0.5187 - val_accuracy: 0.8130\n",
            "Epoch 19/20\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.5248 - accuracy: 0.8065 - val_loss: 0.5221 - val_accuracy: 0.8130\n",
            "Epoch 20/20\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4877 - accuracy: 0.8086 - val_loss: 0.5079 - val_accuracy: 0.8130\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "0.8130081300813008\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-77-fdd9941b1fd7>:19: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  prediction_int=prediction_int.astype(np.int)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Regularization\n",
        "Since neural networks are very complex, there is a high chance of overfitting. This\n",
        "is where regularization comes into the picture. We are already aware of L1 and L2\n",
        "regularization techniques.\n",
        "L1 and L2 regularization\n",
        "Lasso (L1) and Ridge (L2) regularization can be done by passing\n",
        "kernel_regularizer argument to the Keras layers using tf.keras.regularizers along\n",
        "with the alpha value (hyperparameter\n",
        "'''\n",
        "\n",
        "from keras import regularizers\n",
        "\n",
        "model=Sequential()\n",
        "model.add(InputLayer(input_shape=(input_neurons,)))\n",
        "model.add(Dense(units=neuron_hidden_layer_1,activation=\"tanh\",kernel_regularizer=regularizers.L1(0.01)))\n",
        "model.add(Dense(units=neuron_hidden_layer_2,activation=\"tanh\",kernel_regularizer=regularizers.L2(0.01)))\n",
        "model.add(Dense(units=output_neurons,activation=\"sigmoid\"))\n",
        "model.summary()\n",
        "model.compile(loss=\"binary_crossentropy\",optimizer=\"adam\",metrics=[\"accuracy\"])\n",
        "model_history=model.fit(xtrain,ytrain,validation_data=(xtest,ytest),epochs=20)\n",
        "prediction=model.predict(xtest)\n",
        "prediction=prediction.reshape(123,)\n",
        "prediction_int=prediction>=0.5\n",
        "prediction_int=prediction_int.astype(np.int)\n",
        "print(accuracy_score(ytest,prediction_int))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vBt5PPtOWFXH",
        "outputId": "8f1e16f7-43b3-4a3f-e276-916cdf6ba3ef"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_31\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_96 (Dense)            (None, 10)                120       \n",
            "                                                                 \n",
            " dense_97 (Dense)            (None, 5)                 55        \n",
            "                                                                 \n",
            " dense_98 (Dense)            (None, 1)                 6         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 181\n",
            "Trainable params: 181\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "16/16 [==============================] - 1s 15ms/step - loss: 0.9723 - accuracy: 0.6701 - val_loss: 0.9762 - val_accuracy: 0.6829\n",
            "Epoch 2/20\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.9496 - accuracy: 0.6823 - val_loss: 0.9533 - val_accuracy: 0.6748\n",
            "Epoch 3/20\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.9284 - accuracy: 0.6843 - val_loss: 0.9326 - val_accuracy: 0.6911\n",
            "Epoch 4/20\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.9084 - accuracy: 0.6904 - val_loss: 0.9129 - val_accuracy: 0.6911\n",
            "Epoch 5/20\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8888 - accuracy: 0.6904 - val_loss: 0.8940 - val_accuracy: 0.6911\n",
            "Epoch 6/20\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.8700 - accuracy: 0.6904 - val_loss: 0.8757 - val_accuracy: 0.6911\n",
            "Epoch 7/20\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8522 - accuracy: 0.6945 - val_loss: 0.8575 - val_accuracy: 0.6911\n",
            "Epoch 8/20\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.8346 - accuracy: 0.6945 - val_loss: 0.8406 - val_accuracy: 0.6911\n",
            "Epoch 9/20\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8175 - accuracy: 0.6986 - val_loss: 0.8241 - val_accuracy: 0.6911\n",
            "Epoch 10/20\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8020 - accuracy: 0.7047 - val_loss: 0.8078 - val_accuracy: 0.6992\n",
            "Epoch 11/20\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7855 - accuracy: 0.7149 - val_loss: 0.7923 - val_accuracy: 0.7073\n",
            "Epoch 12/20\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7709 - accuracy: 0.7149 - val_loss: 0.7777 - val_accuracy: 0.7073\n",
            "Epoch 13/20\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7566 - accuracy: 0.7210 - val_loss: 0.7634 - val_accuracy: 0.7073\n",
            "Epoch 14/20\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.7425 - accuracy: 0.7312 - val_loss: 0.7497 - val_accuracy: 0.7154\n",
            "Epoch 15/20\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.7293 - accuracy: 0.7373 - val_loss: 0.7363 - val_accuracy: 0.7236\n",
            "Epoch 16/20\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7161 - accuracy: 0.7475 - val_loss: 0.7237 - val_accuracy: 0.7317\n",
            "Epoch 17/20\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.7043 - accuracy: 0.7515 - val_loss: 0.7115 - val_accuracy: 0.7398\n",
            "Epoch 18/20\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6935 - accuracy: 0.7739 - val_loss: 0.7003 - val_accuracy: 0.7805\n",
            "Epoch 19/20\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6820 - accuracy: 0.7923 - val_loss: 0.6885 - val_accuracy: 0.7805\n",
            "Epoch 20/20\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6713 - accuracy: 0.7963 - val_loss: 0.6776 - val_accuracy: 0.7967\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "0.7967479674796748\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-83-39341519d54a>:14: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  prediction_int=prediction_int.astype(np.int)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#batch normalization\n",
        "from keras.layers import BatchNormalization\n",
        "\n",
        "\n",
        "\n",
        "model=Sequential()\n",
        "model.add(InputLayer(input_shape=(input_neurons,)))\n",
        "model.add(Dense(units=neuron_hidden_layer_1,activation=\"tanh\"))\n",
        "model.add(Dense(units=neuron_hidden_layer_2,activation=\"tanh\"))\n",
        "model.add(Dense(units=output_neurons,activation=\"sigmoid\"))\n",
        "model.summary()\n",
        "model.compile(loss=\"binary_crossentropy\",optimizer=\"Adam\",metrics=[\"accuracy\"])\n",
        "model_history=model.fit(xtrain,ytrain,validation_data=(xtest,ytest),epochs=20)\n",
        "prediction=model.predict(xtest)\n",
        "prediction=prediction.reshape(123,)\n",
        "prediction_int=prediction>=0.5\n",
        "prediction_int=prediction_int.astype(int)\n",
        "print(accuracy_score(ytest,prediction_int))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bn6ha2d7O_0I",
        "outputId": "2c2e6dff-ad3b-4903-faa2-0dac875f1b69"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_30\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_93 (Dense)            (None, 10)                120       \n",
            "                                                                 \n",
            " dense_94 (Dense)            (None, 5)                 55        \n",
            "                                                                 \n",
            " dense_95 (Dense)            (None, 1)                 6         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 181\n",
            "Trainable params: 181\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "16/16 [==============================] - 1s 15ms/step - loss: 0.7603 - accuracy: 0.4766 - val_loss: 0.7447 - val_accuracy: 0.5610\n",
            "Epoch 2/20\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6909 - accuracy: 0.5743 - val_loss: 0.6911 - val_accuracy: 0.6260\n",
            "Epoch 3/20\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6536 - accuracy: 0.6477 - val_loss: 0.6676 - val_accuracy: 0.6585\n",
            "Epoch 4/20\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6363 - accuracy: 0.6721 - val_loss: 0.6556 - val_accuracy: 0.6585\n",
            "Epoch 5/20\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6287 - accuracy: 0.6864 - val_loss: 0.6468 - val_accuracy: 0.6585\n",
            "Epoch 6/20\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.6214 - accuracy: 0.6864 - val_loss: 0.6400 - val_accuracy: 0.6585\n",
            "Epoch 7/20\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6150 - accuracy: 0.6884 - val_loss: 0.6325 - val_accuracy: 0.6585\n",
            "Epoch 8/20\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6085 - accuracy: 0.6925 - val_loss: 0.6258 - val_accuracy: 0.6667\n",
            "Epoch 9/20\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6026 - accuracy: 0.6945 - val_loss: 0.6193 - val_accuracy: 0.6829\n",
            "Epoch 10/20\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.5966 - accuracy: 0.6965 - val_loss: 0.6134 - val_accuracy: 0.6992\n",
            "Epoch 11/20\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.5913 - accuracy: 0.6986 - val_loss: 0.6075 - val_accuracy: 0.6992\n",
            "Epoch 12/20\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.5853 - accuracy: 0.6986 - val_loss: 0.6019 - val_accuracy: 0.6992\n",
            "Epoch 13/20\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.5801 - accuracy: 0.7088 - val_loss: 0.5959 - val_accuracy: 0.6992\n",
            "Epoch 14/20\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.5745 - accuracy: 0.7169 - val_loss: 0.5906 - val_accuracy: 0.7073\n",
            "Epoch 15/20\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.5691 - accuracy: 0.7169 - val_loss: 0.5855 - val_accuracy: 0.6911\n",
            "Epoch 16/20\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.5639 - accuracy: 0.7251 - val_loss: 0.5800 - val_accuracy: 0.6992\n",
            "Epoch 17/20\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.5588 - accuracy: 0.7373 - val_loss: 0.5752 - val_accuracy: 0.7236\n",
            "Epoch 18/20\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.5535 - accuracy: 0.7413 - val_loss: 0.5697 - val_accuracy: 0.7398\n",
            "Epoch 19/20\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.5481 - accuracy: 0.7454 - val_loss: 0.5644 - val_accuracy: 0.7398\n",
            "Epoch 20/20\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.5434 - accuracy: 0.7515 - val_loss: 0.5588 - val_accuracy: 0.7398\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "0.7398373983739838\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2PmYQCYHO_2T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NZcWzpf4IwKq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sbDZK6k43bg0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}